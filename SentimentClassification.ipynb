{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,numpy,pandas,nltk\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
    "from nltk.corpus import stopwords #import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "# from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0           is so sad for my APL friend.............\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          1                            omg its already 7:30 :O\n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baca data excel dengan pandas\n",
    "dataset = pandas.read_excel('data/traindataset.xlsx')\n",
    "sntm = dataset[\"Sentiment\"].tolist()\n",
    "sntmtxt = dataset[\"SentimentText\"].tolist()\n",
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>' @crewislife  you want to start the morning l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@cybervenus http://twitpic.com/75kwb ~ LOL Lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@dandelionas is making fettucini and garlic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@danregal  tell @pfont i said Happy BDay!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@dreamingspires. there r many gr8 science car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          1  ' @crewislife  you want to start the morning l...\n",
       "1          1   @cybervenus http://twitpic.com/75kwb ~ LOL Lu...\n",
       "2          1   @dandelionas is making fettucini and garlic b...\n",
       "3          1        @danregal  tell @pfont i said Happy BDay!! \n",
       "4          0   @dreamingspires. there r many gr8 science car..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest = pandas.read_excel('data/testdataset.xlsx')\n",
    "sntmtest = datatrain[\"Sentiment\"].tolist()\n",
    "sntmtxttest = datatrain[\"SentimentText\"].tolist()\n",
    "# datatrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "0    105\n",
      "1     44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#View berdasar topic\n",
    "groupby= dataset.groupby('Sentiment').size()\n",
    "print (groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cek data dan normalisasi\n",
    "#cek bila ada yang kosong\n",
    "shape_check= dataset['SentimentText'].shape\n",
    "null_check=dataset.isnull()\n",
    "null_sum=dataset.isnull().sum()\n",
    "\n",
    "# print (shape_check)\n",
    "# print (null_check)\n",
    "# print (null_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop/Hapus data yang kosong\n",
    "modifiedData = dataset.dropna()\n",
    "\n",
    "shape_check= modifiedData['SentimentText'].shape\n",
    "null_check=modifiedData.isnull()\n",
    "null_sum=modifiedData.isnull().sum()\n",
    "\n",
    "#Save Data yang sudah dimodifikasi ->opsional\n",
    "modifiedData.to_csv('modifiedData.csv',index=False)\n",
    "\n",
    "# print (shape_check)\n",
    "# print (null_check)\n",
    "# print (null_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sntm = dataset[\"Sentiment\"].tolist()\n",
    "sntmtxt = dataset[\"SentimentText\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "        smtr = ' '.join(re.sub(r'@[A-Za-z0-9]+','',data).split()) \n",
    "        smtr = ' '.join(re.sub('https?://[A-Za-z0-9./]+','',smtr).split())\n",
    "        smtr = ' '.join(re.sub(\"[^a-zA-Z]\", \" \", smtr).split())\n",
    "        smtr = ' '.join(re.sub(\"RT\", \" \", smtr).split())\n",
    "        smtr = smtr.lower().split()\n",
    "#         new_string =  re.sub(r\"[\\W]\", \" \", str)\n",
    "        return smtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned= []\n",
    "i = 0\n",
    "while i < len(sntmtxt):\n",
    "    result = clean_data(sntmtxt[i])\n",
    "    result = ' '.join(result)\n",
    "    cleaned.append(result)\n",
    "    i += 1\n",
    "    \n",
    "# print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def stpword(str):\n",
    "    word_tokens = word_tokenize(str) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "    filtered_sentence = [] \n",
    "    \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "stpwrd = []\n",
    "i = 0\n",
    "while i < len(sntmtxt):\n",
    "    new = ' '.join(stpword(cleaned[i]))\n",
    "    stpwrd.append(new)\n",
    "    i += 1\n",
    "    \n",
    "# print(stpwrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(cleaned)\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming English\n",
    "# def stemmingEnglish(str):\n",
    "#     porter_stemmer = PorterStemmer()\n",
    "#     words = word_tokenize(str)\n",
    "#     result = list()\n",
    "#     for word in words:\n",
    "#         result.append(porter_stemmer.stem(word))\n",
    "#     return ' '.join(result)\n",
    "\n",
    "# stem = []\n",
    "# i = 0\n",
    "# while i < len(sntmtxt):\n",
    "#     new = ' '.join(stemmingEnglish(stpwrd[i]))\n",
    "#     stem.append(new)\n",
    "#     i += 1\n",
    "    \n",
    "# print(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []\n",
    "j = 0\n",
    "while j < len(sntmtxt):\n",
    "    train = (stpwrd[j], sntm[j])\n",
    "    record.append(train)\n",
    "    j += 1\n",
    "    \n",
    "# print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "nbc = NaiveBayesClassifier(record)\n",
    "#cl.classify(\"I feel amazing!\")\n",
    "blob = TextBlob(\"i hate you\", classifier=nbc)\n",
    "print(blob.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "nbc = NaiveBayesClassifier(record)\n",
    "#cl.classify(\"I feel amazing!\")\n",
    "blob = TextBlob(\"beautiful\", classifier=nbc)\n",
    "print(blob.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 1\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n",
      "0 === 0\n"
     ]
    }
   ],
   "source": [
    "cleanedtest= []\n",
    "i = 0\n",
    "while i < len(sntmtxttest):\n",
    "    result = clean_data(sntmtxttest[i])\n",
    "    result = ' '.join(result)\n",
    "    cleanedtest.append(result)\n",
    "    i += 1\n",
    "\n",
    "stpwrdtest = []\n",
    "i = 0\n",
    "while i < len(sntmtxttest):\n",
    "    new = ' '.join(stpword(cleanedtest[i]))\n",
    "    stpwrdtest.append(new)\n",
    "    i += 1    \n",
    "\n",
    "testing = NaiveBayesClassifier(record)\n",
    "j = 0\n",
    "while j < len(datatest):\n",
    "    tb = TextBlob(stpwrdtest[j], classifier=nbc)\n",
    "    print(blob.classify() , \"===\" , sntmtest[j])\n",
    "    j += 1\n",
    "\n",
    "# mx = NaiveBayesClassifier(dicti)\n",
    "# j = 0\n",
    "# while j < len(testset):\n",
    "#     blob = TextBlob(tee[j], classifier=cls)\n",
    "#     print(blob.classify() + \"---\" + senuntuktest[j])\n",
    "#     j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
